#Project 2 code
from data import load_dataset, filter_dataset
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA, KernelPCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import pandas as pd

# Import dataset
X_full,y_full = load_dataset()
X,y = filter_dataset(X_full,y_full,"1,7")
X = X / 255

print(X.shape)
print(y.shape)

max(X_full[0]), max(X[0])

###########
y = np.array(y, dtype=int)
###########


# Plot the squared images
fig, ax = plt.subplots(1, 2)
ax[0].imshow(X[0].reshape(28,28), cmap='gray')
ax[1].imshow(X[45].reshape(28,28), cmap='gray')
plt.show()


# Perform PCA on the dataset
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
print("Total variance capture by PCA: ", sum(pca.explained_variance_ratio_))
pca = PCA(n_components=1)
X_pca = pca.fit_transform(X)

# Study effect of n_components on explained variance ratio
nums = np.arange(50)
 
var_ratio = []
for num in nums:
  pca = PCA(n_components=num)
  X_pca = pca.fit_transform(X)
  var_ratio.append(np.sum(pca.explained_variance_ratio_))

plt.figure(figsize=(6,4),dpi=150)
plt.grid()
plt.plot(nums,var_ratio,marker='o')
plt.xlabel('n_components')
plt.ylabel('Explained variance ratio')
plt.title('n_components vs. Explained Variance Ratio')



# LDA proves to be much better, since we care more about class separation and nor variance
lda = LinearDiscriminantAnalysis(n_components=1)
Xs = StandardScaler().fit_transform(X)
X_lda = lda.fit_transform(Xs, y)
print("Total variance capture by LDA: ", sum(lda.explained_variance_ratio_))
print("New feature-space shape: ", X_lda.shape)



# Plot LDA
# Scatter plot along a single axis (1D)
plt.figure(figsize=(8, 5))
sns.kdeplot(x=X_lda.ravel(), hue=y, fill=True, palette=['blue', 'red'])
plt.xlabel("LDA Feature")
plt.ylabel("Density")
plt.title("LDA Feature Distribution by Class")
plt.legend(["Digit 1", "Digit 7"])
plt.show()



# import sys
# #!{sys.executable} -m pip install tqdm
# !{sys.executable} -m pip install modAL
# !{sys.executable} -m pip install modal

from modAL.disagreement import vote_entropy_sampling
from modAL.models import ActiveLearner, Committee


from sklearn.ensemble import RandomForestClassifier
from joblib import Parallel, delayed
import itertools as it
from sklearn.model_selection import train_test_split
from collections import namedtuple
from tqdm.notebook import tqdm, trange
#####
from tqdm import tqdm
#######


ModelClass=RandomForestClassifier

SEED = 1 # Set our RNG seed for reproducibility.

n_queries = 75 # You can lower this to decrease run time

# You can increase this to get error bars on your evaluation.
# You probably need to use the parallel code to make this reasonable to compute
n_repeats = 3

ResultsRecord = namedtuple('ResultsRecord', ['estimator', 'query_id', 'score'])

###########
y = np.array(y, dtype=int)  # Ensure labels are integers before splitting
X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=1/3, random_state=1)
##########
# X_train, X_test, y_train, y_test = train_test_split(
#     X_lda, y, test_size=1/3, random_state=SEED)

# in case repetitions are desired
permutations=[np.random.permutation(X_train.shape[0]) for _ in range(n_repeats)]


# PARRALLEL VERSION OF THE CELL ABOVE
# Use this instead if you aren't afraid of working with parallel code or want to learn.

n_members=[2, 4, 8, 16]

def oracle(query_idx):
   return y_train[query_idx]


def active_learning_loop(committee, X_pool, y_pool, X_test, y_test):
    """Runs the active learning process by querying the most uncertain samples."""
    performance = []
    
    for i_query in tqdm(range(n_queries), desc="Active Learning Progress"):
        query_idx, query_instance = committee.query(X_pool)
        
        # The oracle provides the true label
        y_new = oracle(query_idx)
        
        # Teach the committee the new label
        committee.teach(X_pool[query_idx].reshape(1, -1), np.array(y_new).reshape(1,))

        # Update classes
        committee._set_classes()

        # Remove the queried sample from the pool
        X_pool = np.delete(X_pool, query_idx, axis=0)
        y_pool = np.delete(y_pool, query_idx)

        # Evaluate performance
        score = committee.score(X_test, y_test)
        performance.append(score)

    return performance

def train_committee(i_repeat, i_members, X_train, y_train):
    y_train = np.array(y_train, dtype=int)  
    committee_results = []
    print('')

    X_pool = X_train.copy()
    y_pool = y_train.copy()
    start_indices = permutations[i_repeat][:10]  

    committee_members = [ActiveLearner(estimator=ModelClass(),
                                       X_training=X_train[start_indices, :],
                                       y_training=y_train[start_indices])
                         for _ in range(i_members)]

    committee = Committee(learner_list=committee_members, query_strategy=vote_entropy_sampling)
    X_pool = np.delete(X_pool, start_indices, axis=0)
    y_pool = np.delete(y_pool, start_indices)

    performance = active_learning_loop(committee, X_pool, y_pool, X_test, y_test)
    
    return performance

result = Parallel(n_jobs=-1)(delayed(train_committee)(i, i_members, X_train, y_train)
                             for i, i_members in it.product(range(n_repeats), n_members))

print('All jobs done')

plt.figure(figsize=(8, 5))
plt.plot(range(1, n_queries + 1), result[0], marker='o', linestyle='-')
plt.xlabel("Number of Queries")
plt.ylabel("Accuracy")
plt.title("Active Learning Performance")
plt.grid(True)
plt.show()
